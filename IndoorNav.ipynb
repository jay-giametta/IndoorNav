{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IndoorNav.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bLh13Dn4DuxW",
        "xpfnNcL4YCVa",
        "JwQvruYLYzgm",
        "lHlpvFruY987"
      ],
      "authorship_tag": "ABX9TyPYAWxu863wAJY3mMSrN3dN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLh13Dn4DuxW"
      },
      "source": [
        "# Unzip training data on Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR2jEAkiDZt1"
      },
      "source": [
        "Import Google Drive module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iMFsp8H0qCA"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtPeDxaMDTKe"
      },
      "source": [
        "Mount the Google Drive that contains the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMziKGIYAceL",
        "outputId": "e3b80706-6e1c-4bf3-dacc-50a5e51b828c"
      },
      "source": [
        "drive.mount(\"/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tREe-g80DkOc"
      },
      "source": [
        "Create a symbolic link (shortcut) to the IndoorNav data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3BlEGrcCtGO"
      },
      "source": [
        "!ln -s \"/gdrive/MyDrive/IndoorNav\" \"/content/data\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iEGEDXMMNA8"
      },
      "source": [
        "Unzip the archived training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0subxF7L6Uf"
      },
      "source": [
        "!unzip data/train.zip -d data/train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HRSkYhZTl-2"
      },
      "source": [
        "Flush the mount to make Colab sync with Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRpuZ9kPSfJU"
      },
      "source": [
        "drive.flush_and_unmount()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpfnNcL4YCVa"
      },
      "source": [
        "# Connect to Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmEh7VdIYCVf"
      },
      "source": [
        "Import Google Drive module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtBTNeW0YCVg"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlhiiUh6YCVh"
      },
      "source": [
        "Mount the Google Drive that contains the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDbOLKUlYCVh",
        "outputId": "6fa06800-1f5e-4c4e-9efa-2c689adb7b66"
      },
      "source": [
        "drive.mount(\"/gdrive\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mC59FznLYCVi"
      },
      "source": [
        "Create a symbolic link (shortcut) to the IndoorNav data from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFhLfdLAYCVi"
      },
      "source": [
        "!ln -s \"/gdrive/MyDrive/IndoorNav\" \"/content/data\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwQvruYLYzgm"
      },
      "source": [
        "# BuildObs Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poAabXiHY56d"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def buildObs(inFName: str, floorID: str):\n",
        "\n",
        "    waypoint_x = 0.0\n",
        "    waypoint_y = 0.0\n",
        "    floor = \"0\"\n",
        "\n",
        "    inFile = open (inFName, \"r\")\n",
        "    inFileLines = inFile.readlines()\n",
        "\n",
        "    names=[\"ts\",\n",
        "           \"floor\",\n",
        "           \"waypoint_x\",\n",
        "           \"waypoint_y\",\n",
        "           \"accel_1\",\n",
        "           \"accel_2\",\n",
        "           \"accel_3\",\n",
        "           \"magnet_1\",\n",
        "           \"magnet_2\",\n",
        "           \"magnet_3\",\n",
        "           \"gyro_1\",\n",
        "           \"gyro_2\",\n",
        "           \"gyro_3\",\n",
        "           \"wifi_1\",\n",
        "           \"wifi_2\",\n",
        "           \"wifi_3\",\n",
        "           \"wifi_4\",\n",
        "           \"wifi_5\",\n",
        "           \"beacon_1\",\n",
        "           \"beacon_2\",\n",
        "           \"beacon_3\",\n",
        "           \"beacon_4\",\n",
        "           \"beacon_5\",\n",
        "           \"beacon_6\",\n",
        "           \"beacon_7\"\n",
        "           ]\n",
        "    dFrame = pd.DataFrame(columns=names)\n",
        "\n",
        "    #Set the floor where 1F or F1 = 0, F2 = 1, and 1B = 01\n",
        "    if \"B\" in (floorID):\n",
        "        floor = str((int(re.findall(\"\\d+\", floorID)[0]) ) * -1)\n",
        "\n",
        "    if \"F\" in (floorID):\n",
        "        floor = str(int(re.findall(\"\\d+\", floorID)[0]) - 1)\n",
        "\n",
        "    #Create rows of data for each observation by timestamp\n",
        "    for i in range(0,len(inFileLines)):\n",
        "\n",
        "        splitLine = inFileLines[i].split()\n",
        "\n",
        "        if splitLine[1] == \"TYPE_WAYPOINT\":\n",
        "\n",
        "            waypoint_x = float(splitLine[2])\n",
        "            waypoint_y = float(splitLine[3])\n",
        "\n",
        "        elif splitLine[1] == \"TYPE_ACCELEROMETER\":\n",
        "\n",
        "            accel_1 = float(splitLine[2])\n",
        "            accel_2 = float(splitLine[3])\n",
        "            accel_3 = float(splitLine[4])\n",
        "\n",
        "            i += 1\n",
        "            splitLine = inFileLines[i].split()\n",
        "\n",
        "            magnet_1 = float(splitLine[2])\n",
        "            magnet_2 = float(splitLine[3])\n",
        "            magnet_3 = float(splitLine[4])\n",
        "\n",
        "            i += 1\n",
        "            splitLine = inFileLines[i].split()\n",
        "\n",
        "            gyro_1 = float(splitLine[2])\n",
        "            gyro_2 = float(splitLine[3])\n",
        "            gyro_3 = float(splitLine[4])\n",
        "\n",
        "            i += 1\n",
        "            splitLine = inFileLines[i].split()\n",
        "\n",
        "            rot_1 = float(splitLine[2])\n",
        "            rot_2 = float(splitLine[3])\n",
        "            rot_3 = float(splitLine[4])\n",
        "\n",
        "            #skip over uncalibrated lines\n",
        "            i += 3\n",
        "\n",
        "            dFrame = dFrame.append({\n",
        "                \"ts\": float(splitLine[0]),\n",
        "                \"floor\" : floor,\n",
        "                \"waypoint_x\": waypoint_x,\n",
        "                \"waypoint_y\": waypoint_y,\n",
        "                \"accel_1\": accel_1,\n",
        "                \"accel_2\": accel_2,\n",
        "                \"accel_3\": accel_3,\n",
        "                \"magnet_1\": magnet_1,\n",
        "                \"magnet_2\": magnet_2,\n",
        "                \"magnet_3\": magnet_3,\n",
        "                \"gyro_1\": gyro_1,\n",
        "                \"gyro_2\": gyro_2,\n",
        "                \"gyro_3\": gyro_3,\n",
        "                \"rot_1\": rot_1,\n",
        "                \"rot_2\": rot_2,\n",
        "                \"rot_3\": rot_3},\n",
        "                ignore_index=True)\n",
        "\n",
        "        elif splitLine[1] == \"TYPE_WIFI\":\n",
        "\n",
        "            dFrame = dFrame.append({\n",
        "                \"ts\": float(splitLine[0]),\n",
        "                \"floor\": floor,\n",
        "                \"waypoint_x\": waypoint_x,\n",
        "                \"waypoint_y\": waypoint_y,\n",
        "                \"wifi_1\": str(splitLine[2]),\n",
        "                \"wifi_2\": str(splitLine[3]),\n",
        "                \"wifi_3\": float(splitLine[4]),\n",
        "                \"wifi_4\": float(splitLine[5]),\n",
        "                \"wifi_5\": float(splitLine[6])},\n",
        "                ignore_index=True)\n",
        "\n",
        "        elif splitLine[1] == \"TYPE_BEACON\":\n",
        "\n",
        "            dFrame = dFrame.append({\n",
        "                \"ts\": float(splitLine[0]),\n",
        "                \"floor\": floor,\n",
        "                \"waypoint_x\": waypoint_x,\n",
        "                \"waypoint_y\": waypoint_y,\n",
        "                \"beacon_1\": str(splitLine[2]),\n",
        "                \"beacon_2\": str(splitLine[3]),\n",
        "                \"beacon_3\": str(splitLine[4]),\n",
        "                \"beacon_4\": float(splitLine[5]),\n",
        "                \"beacon_5\": float(splitLine[6]),\n",
        "                \"beacon_6\": float(splitLine[7]),\n",
        "                \"beacon_7\": str(splitLine[8])},\n",
        "                ignore_index=True)\n",
        "\n",
        "    return dFrame.copy()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHlpvFruY987"
      },
      "source": [
        "# CleanObs Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQjUWqSVZENF"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def cleanObs(dFrame: pd.DataFrame):\n",
        "\n",
        "    #perform bidirectional linear interpolation to fill in missing values\n",
        "    dFrame = dFrame.interpolate(limit_direction=\"both\")\n",
        "\n",
        "    for column in dFrame.columns:\n",
        "\n",
        "        if dFrame[column].dtype == \"float64\":\n",
        "\n",
        "            #if there are any leftover missing float values replace them with the mean\n",
        "            dFrame[column] = dFrame[column].replace(np.nan,dFrame[column].mean())\n",
        "\n",
        "        else:\n",
        "\n",
        "            #if there are any missing string values replace them with NULL\n",
        "            dFrame[column] = dFrame[column].replace(np.nan, \"NULL\")\n",
        "\n",
        "    return dFrame"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP2vndt0ZOHp"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0mqjHXgZR0r",
        "outputId": "aa75e1fb-6512-4d4e-fa9e-f79dbfa2f0b3"
      },
      "source": [
        "import pandas as pd\n",
        "import random as rnd\n",
        "\n",
        "from os import listdir\n",
        "from os import remove\n",
        "from os.path import isfile\n",
        "\n",
        "path = \"data/train\"\n",
        "\n",
        "obsProgFile = \"data/obsProg.txt\"\n",
        "obsProgRead = open(obsProgFile, \"r\").read()\n",
        "\n",
        "for file in listdir(path):\n",
        "\n",
        "    if((file + \"\\n\") not in obsProgRead):\n",
        "\n",
        "      open(obsProgFile,\"a+\").write(file + \"\\n\")\n",
        "\n",
        "      for floor in listdir(path + \"/\" + file):\n",
        "\n",
        "          folder = listdir(path + \"/\" + file + \"/\" + floor)\n",
        "\n",
        "          #take a random sampling of five files from each folder\n",
        "          for i in rnd.sample(range(0, len(folder)), 5):\n",
        "\n",
        "              fileName = folder[i]\n",
        "\n",
        "              if \"txt\" in fileName:\n",
        "\n",
        "                  fullName = path + \"/\" + file + \"/\" + floor + \"/\" + fileName\n",
        "                  newName = (path + \"/_processed/\" + fileName).replace(\"txt\",\"csv\")\n",
        "\n",
        "                  print(\"Processing \" + fullName + \":\")\n",
        "                  print(\"Building observations...\")\n",
        "                  dFrame = pd.DataFrame(buildObs(fullName, floor))\n",
        "\n",
        "                  print(\"Cleaning observations...\")\n",
        "                  dFrame = pd.DataFrame(cleanObs(dFrame))\n",
        "\n",
        "                  print(\"Writing \" + newName + \"...\")\n",
        "                  dFrame.to_csv(newName, index=False)\n",
        "\n",
        "                  print(\"Complete.\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing data/train/5a0546857ecc773753327266/B1/5e15bf8ef4c3420006d5233f.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e15bf8ef4c3420006d5233f.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/B1/5e1581d51506f2000638fc80.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e1581d51506f2000638fc80.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/B1/5e1580b41506f2000638fc5c.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e1580b41506f2000638fc5c.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/B1/5e1581cbf4c3420006d52101.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e1581cbf4c3420006d52101.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/B1/5e158ef61506f2000638fd1f.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e158ef61506f2000638fd1f.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/F1/5e15a2c4f4c3420006d521cb.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e15a2c4f4c3420006d521cb.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/F1/5e15b390f4c3420006d522eb.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e15b390f4c3420006d522eb.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/F1/5e15aff31506f2000638fe3c.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e15aff31506f2000638fe3c.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/F1/5e15ab16f4c3420006d5224e.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e15ab16f4c3420006d5224e.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/F1/5e15ab751506f2000638fe04.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5e15ab751506f2000638fe04.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/F2/5d1340afffe23f0008605137.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5d1340afffe23f0008605137.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/F2/5dccfd13c04f060006e6e4f5.txt:\n",
            "Building observations...\n",
            "Cleaning observations...\n",
            "Writing data/train/_processed/5dccfd13c04f060006e6e4f5.csv...\n",
            "Complete.\n",
            "\n",
            "Processing data/train/5a0546857ecc773753327266/F2/5d1340bee5d8ea0008e38ffe.txt:\n",
            "Building observations...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}